r"""
A script to visualise the output generated by LikelihoodLandscape.

Author: Philipp Windischhofer
Date:   August 2019
Email:  philipp.windischhofer@cern.ch

Description:
    This script takes the output trees produced by runLikelihoodLandscape, retrieves
    the best-fit point and the evaluated PNLL values, and visualises them in a way
    that is appropriate for the corresponding dimensionality.

    * for 1D scans: draw the profiled likelihood and mark the 1\sigma and 2\sigma confidence intervals
    * for 2D scans: draw the 2D-contour corresponding to the 1\sigma confidence interval and mark
                    the best-fit position.

    In both cases, the results for the corresponding Asimov dataset is shown as well.
"""


import ROOT
ROOT.gROOT.SetBatch(True)

import os
import numpy as np
from array import array
from argparse import ArgumentParser

from analysisPlottingConfig import Config

# some private helper functions
def _drawText(x, y, text, color = ROOT.kBlack, fontsize = 0.05, font = 42, doNDC = True, alignment = 12):
    """
    Put a TLatex at a certain position.
    """
    tex = ROOT.TLatex()
    if doNDC:
        tex.SetNDC()
    ROOT.SetOwnership(tex, False)
    tex.SetTextAlign(alignment)
    tex.SetTextSize(fontsize)
    tex.SetTextFont(font)
    tex.SetTextColor(color)
    tex.DrawLatex(x, y, text)

def _drawATLASLabel(x, y, text, doNDC = True, fontsize = 0.07):
    """
    Draw a nice ATLAS label.
    """
    _drawText(x, y, "ATLAS", fontsize = fontsize, font = 72, doNDC = doNDC, alignment = 13)
    _drawText(x + 0.12, y, text, fontsize = fontsize, font = 42, doNDC = doNDC, alignment = 13)

def operator_namer(name, plotconf):
    library = plotconf.EFT_operator_labels

    if name in library:
        return library[name]
    else:
        return name

def array2hist(array, histname = "hist", default_value = None):
    """
    Converts the contents of a 2d-numpy array into a histogram.
    Assume the data is organised as (x, y, z). Implement it here instead
    of using root_numpy to avoid picking up this additional dependency.
    """
    # get the required numbers of bins ...
    number_bins_x = np.shape(array)[0]
    number_bins_y = np.shape(array)[1]

    # ... and the axis ranges
    xmin = np.min(array[:,:,0])
    xmax = np.max(array[:,:,0])
    avg_bw_x = (xmax - xmin) / number_bins_x
    ymin = np.min(array[:,:,1])
    ymax = np.max(array[:,:,1])
    avg_bw_y = (ymax - ymin) / number_bins_y

    # create the actual histogram
    hist = ROOT.TH2D(histname, histname,
                     number_bins_x, xmin - avg_bw_x / 2, xmax + avg_bw_x / 2,
                     number_bins_y, ymin - avg_bw_y / 2, ymax + avg_bw_y / 2)
    ROOT.SetOwnership(hist, False)

    # set the default value
    if default_value:
        for bin_ind in range(hist.GetSize()):
            hist.SetBinContent(bin_ind, default_value)

    # fill the histogram
    array_flat = np.reshape(array, (-1, 3))
    for cur_ind in range(array_flat.shape[0]):
        cur_point = array_flat[cur_ind, :]

        # ignore NaNs in the input data
        if sum(np.isnan(cur_point)) > 0:
            continue

        cur_bin = hist.FindBin(cur_point[0], cur_point[1])
        hist.SetBinContent(cur_bin, cur_point[2])

    return hist

def GetContours(data, conto_level):
    """
    Generate a given contour curve, given some data (i.e. tuples of (x,y,z)-coordinates)
    """
    # first, create a histogram representation of the input data
    hist = array2hist(data, default_value = np.nanmax(data))

    # get the actual contour lines
    hist.SetContour(len(conto_level), array('d', conto_level))
    hist.Draw("CONT Z LIST")
    ROOT.gPad.Update()

    contours = ROOT.gROOT.GetListOfSpecials().FindObject("contours")
    if not contours:
        return []

    return [cur.Clone() for cur in contours]

def Plot2DHeatmap(data, label, outfile_path, xlabel = "", ylabel = "", zlabel = "", bestfit = [], inner_label = ""):
    plotconf = Config(options = [])

    print("starting to plot")

    # set ATLAS plotting style
    macros_dir = os.path.join(os.environ["WORKDIR"], "macros")
    ROOT.gROOT.LoadMacro(os.path.join(macros_dir, "AtlasStyle.C"))
    ROOT.gROOT.LoadMacro(os.path.join(macros_dir, "AtlasUtils.C"))
    ROOT.SetAtlasStyle()
    ROOT.gStyle.SetEndErrorSize(7.0);

    canv = ROOT.TCanvas("canv", "canv", 800, 600)
    ROOT.SetOwnership(canv, False)
    canv.SetRightMargin(0.18)
    canv.cd()

    # set a nice color scheme
    ROOT.gStyle.SetPalette(ROOT.kBird)
    hist = array2hist(data)
    hist.Draw("colz")

    hist.GetXaxis().SetTitle(xlabel)
    hist.GetYaxis().SetTitle(ylabel)
    hist.GetZaxis().SetTitle(zlabel)

    bestfit_marker = ROOT.TMarker(bestfit[0], bestfit[1], 34)
    bestfit_marker.SetMarkerColor(ROOT.kWhite)
    bestfit_marker.SetMarkerSize(1.5)
    bestfit_marker.Draw()

    inner_label_x = 0.45
    inner_label_y = 0.89
    _drawATLASLabel(inner_label_x, inner_label_y, plotconf.ATLAS_suffix, fontsize = 0.045)
    _drawText(inner_label_x, inner_label_y - 0.1, inner_label, fontsize = 0.045)

    label_x = 0.19
    label_y = 0.20
    _drawText(label_x, label_y, label, fontsize = 0.045)

    canv.SaveAs(outfile_path)

def Plot2DContours(data, labels, colors, outfile_path, contour_levels, contour_labels, cont_ls = [], xlabel = "", ylabel = "", bestfit = {}, inner_label = ""):
    plotconf = Config(options = [])

    print("starting to plot")

    if len(bestfit) != len(data):
        bestfit = [None for cur in data]

    # set ATLAS plotting style
    macros_dir = os.path.join(os.environ["WORKDIR"], "macros")
    ROOT.gROOT.LoadMacro(os.path.join(macros_dir, "AtlasStyle.C"))
    ROOT.gROOT.LoadMacro(os.path.join(macros_dir, "AtlasUtils.C"))
    ROOT.SetAtlasStyle()
    ROOT.gStyle.SetEndErrorSize(7.0);

    canv = ROOT.TCanvas("canv", "canv", 800, 600)
    ROOT.SetOwnership(canv, False)

    mg = ROOT.TMultiGraph()
    ROOT.SetOwnership(mg, False)

    leg = ROOT.TLegend(0.23, 0.19, 0.46, 0.2 + len(labels) * 0.137)
    ROOT.SetOwnership(leg, False)
    leg.SetFillStyle(0)
    leg.SetBorderSize(0)
    leg.SetTextFont(42)
    leg.SetTextSize(0.045)

    bestfit_markers = []
    sm_pred = []

    for cur_data, cur_label, cur_color, cur_bestfit in zip(data, labels, colors, bestfit):
        canv.cd()

        contours = GetContours(cur_data, contour_levels)

        print(f"contours = {contours}")

        for cont, cont_label, cur_ls in zip(contours, contour_labels, cont_ls):
            for cont_part in cont:
                cur_cont_part = cont_part.Clone()
                cur_cont_part.SetLineColor(cur_color)
                cur_cont_part.SetLineStyle(cur_ls)
                #cur_cont_part.SetLineWidth(cur_lw)
                mg.Add(cur_cont_part)

            leg.AddEntry(cur_cont_part, f"{cur_label} {cont_label}", "l")

        cur_bestfit_marker = ROOT.TMarker(cur_bestfit[0], cur_bestfit[1], 34)
        cur_bestfit_marker.SetMarkerColor(ROOT.kBlue)
        cur_bestfit_marker.SetMarkerSize(1.5)
        bestfit_markers.append(cur_bestfit_marker)
        leg.AddEntry(cur_bestfit_marker, f"{cur_label} best fit", "p")
        
        sm_marker = ROOT.TMarker(1,1,30)
        sm_marker.SetMarkerColor(ROOT.kRed)
        sm_marker.SetMarkerSize(1.7)
        sm_pred.append(sm_marker)
        leg.AddEntry(sm_marker, "SM pred.", "p")
        

    canv.cd()
    mg.Draw("al")

    # increase the x and y axis range a bit to nicely plot the entire contour
    zoomfact_x = 1.
    zoomfact_y = 1.1
    mg.GetXaxis().SetLimits(zoomfact_x * mg.GetXaxis().GetXmin(), zoomfact_x * mg.GetXaxis().GetXmax())
    mg.SetMinimum(0* mg.GetYaxis().GetXmin())
    mg.SetMaximum(zoomfact_y * mg.GetYaxis().GetXmax())
    mg.Draw("al")

    for cur_marker in bestfit_markers:
        cur_marker.Draw()
    
    for preds in sm_pred:
    	preds.Draw()

    mg.GetXaxis().SetTitle(xlabel)
    mg.GetXaxis().SetTitleSize(0.06)
    mg.GetXaxis().SetTitleOffset(1.2)
    mg.GetYaxis().SetTitle(ylabel)
    mg.GetYaxis().SetTitleSize(0.06)
    mg.GetYaxis().SetTitleOffset(1.2)

    leg.Draw()

    # add labels
    inner_label_x = 0.60
    inner_label_y = 0.89
    _drawATLASLabel(inner_label_x, inner_label_y, plotconf.ATLAS_suffix, fontsize = 0.045)
    _drawText(inner_label_x, inner_label_y - 0.1, inner_label, fontsize = 0.045)

    canv.SaveAs(outfile_path)

    outfile_png_path = os.path.splitext(outfile_path)[0] + ".png"
    canv.SaveAs(outfile_png_path) # always also save as png for webpage

    outfile_png_path = os.path.splitext(outfile_path)[0] + ".C"
    canv.SaveAs(outfile_png_path) # always also save as png for webpage

def Plot1DProfile(xvals, yvals, labels, colors, outfile_path, twodelta, xlabel = "", ylabel = "", inner_label = "", lw = [], ls = [], xlim = [], ylim = [0.0, 3.0]):
    if len(lw) != len(xvals):
        lw = [1 for cur in xvals]

    if len(ls) != len(xvals):
        ls = [1 for cur in xvals]

    plotconf = Config(options = [])

    # set ATLAS plotting style
    macros_dir = os.path.join(os.environ["WORKDIR"], "macros")
    ROOT.gROOT.LoadMacro(os.path.join(macros_dir, "AtlasStyle.C"))
    ROOT.gROOT.LoadMacro(os.path.join(macros_dir, "AtlasUtils.C"))
    ROOT.SetAtlasStyle()
    ROOT.gStyle.SetEndErrorSize(7.0);

    canv = ROOT.TCanvas("canv", "canv", 800, 600)
    ROOT.SetOwnership(canv, False)

    mg = ROOT.TMultiGraph()
    ROOT.SetOwnership(mg, False)

    leg = ROOT.TLegend(0.37, 0.67 - len(labels) * 0.05, 0.57, 0.67)
    ROOT.SetOwnership(leg, False)
    leg.SetBorderSize(0)
    leg.SetFillStyle(0)
    leg.SetTextFont(42)
    leg.SetTextSize(0.045)

    domain_mins = []
    domain_maxs = []
    for cur_xvals, cur_yvals, cur_label, cur_color, cur_lw, cur_ls in zip(xvals, yvals, labels, colors, lw, ls):

        # find reasonable values for the axis range
        cur_xvals = np.array(cur_xvals)
        cur_yvals = np.array(cur_yvals)
        domain_mins.append(np.min(cur_xvals[cur_yvals < 3.0]))
        domain_maxs.append(np.max(cur_xvals[cur_yvals < 3.0]))

        sorter = np.argsort(cur_xvals)
        cur_xval_data = array('d', cur_xvals[sorter])
        cur_yval_data = array('d', cur_yvals[sorter])

        cur_graph = ROOT.TGraph(len(cur_xval_data), cur_xval_data, 2 * cur_yval_data if twodelta else cur_yval_data)
        ROOT.SetOwnership(cur_graph, False)
        cur_graph.SetLineColor(cur_color)
        cur_graph.SetLineStyle(cur_ls)
        cur_graph.SetLineWidth(cur_lw)

        mg.Add(cur_graph)
        leg.AddEntry(cur_graph, cur_label, "l")

    canv.cd()
    mg.Draw("al")

    if ylim:
        mg.GetYaxis().SetRangeUser(ylim[0], 2 * ylim[1] if twodelta else ylim[1])

    if not xlim:
        # if not given explicitly, attempt to zoom in on the interesting region
        xlim = [1.3 * np.min(domain_mins), 1.3 * np.max(domain_maxs)]

    print(f"setting x-axis limits: {xlim}")
    mg.GetXaxis().SetRangeUser(xlim[0], xlim[1])

    mg.GetXaxis().SetTitle(xlabel)
    mg.GetYaxis().SetTitle(ylabel)

    # draw additional n\sigma lines
    for CL, linepos in zip([68, 95], [0.494475, 1.92072]):

        ROOT.gPad.Modified()
        ROOT.gPad.Update()
        cur_line = ROOT.TLine(ROOT.gPad.GetUxmin(), 2 * linepos if twodelta else linepos,
                              ROOT.gPad.GetUxmax(), 2 * linepos if twodelta else linepos)
        ROOT.SetOwnership(cur_line, False)
        cur_line.SetLineWidth(2)
        cur_line.SetLineStyle(2)
        cur_line.SetLineColor(ROOT.kGray)
        cur_line.Draw("same")

        _drawText(ROOT.gPad.GetUxmin() + (ROOT.gPad.GetUxmax() - ROOT.gPad.GetUxmin()) * 0.04, linepos + 0.07, f"{CL}% CL", color = ROOT.kGray, fontsize = 0.045, font = 42, doNDC = False, alignment = 12)

    leg.Draw()

    ROOT.gPad.RedrawAxis()

    # add ATLAS label
    inner_label_x = 0.37
    inner_label_y = 0.87
    _drawATLASLabel(inner_label_x, inner_label_y, plotconf.ATLAS_suffix, fontsize = 0.045)
    _drawText(inner_label_x, inner_label_y - 0.1, inner_label, fontsize = 0.045)

    canv.SaveAs(outfile_path)

def Tree2Dict(treefile_path, tree_name = "NLLscan"):
    if not os.path.exists(treefile_path):
        raise OSError(f"Error: file '{treefile_path}' does not exist!")

    infile = ROOT.TFile(treefile_path, 'READ')
    ROOT.SetOwnership(infile, False)
    intree = infile.Get(tree_name)

    available_columns = [key.GetName() for key in intree.GetListOfBranches()]
    retdict = {col: [] for col in available_columns}

    for row in intree:
        for col in available_columns:
            retdict[col].append(getattr(row, col))

    infile.Close()
    return retdict

def RemoveOutliers(xvals, zvals, cut = lambda xval, zval: True if zval < 50 else False):
    new_xvals = []
    new_zvals = []

    xvals = list(map(list, zip(*xvals)))

    for ind, cur_zval in enumerate(zvals):
        if cut(xvals[ind], zvals[ind]):
            new_xvals.append(xvals[ind])
            new_zvals.append(zvals[ind])

    new_xvals = list(map(list, zip(*new_xvals)))
    return new_xvals, new_zvals

def Interpolate(xvals, yvals, zvals, number_points = 64.0):
    from scipy.interpolate import griddata

    min_x = np.min(xvals)
    max_x = np.max(xvals)
    step_x = (max_x - min_x) / number_points

    min_y = np.min(yvals)
    max_y = np.max(yvals)
    step_y = (max_y - min_y) / number_points

    grid_x, grid_y = np.mgrid[min_x:max_x:step_x,
                              min_y:max_y:step_y]

    inpoints = np.transpose(np.array([xvals, yvals]))

    # do the interpolation
    grid_z = griddata(inpoints, zvals, (grid_x, grid_y), method = 'linear')

    # return an array of (x, y, z) triples
    retval = np.transpose(np.array([grid_x, grid_y, grid_z]))
    return retval

def GetConfidenceInterval(xvals, yvals, threshold, number_points = 2000):
    """
    Extracts confidence intervals in parameter space.
    """

    # ensure that we have flat numpy array to deal with
    xvals = np.array(xvals).flatten()
    yvals = np.array(yvals).flatten()

    # first, get a smooth interpolation of the likelihood curve
    xmin = np.min(xvals)
    xmax = np.max(xvals)

    # make sure that everything is sorted
    sortind = np.argsort(xvals)
    xvals = xvals[sortind]
    yvals = yvals[sortind]

    # interpolate onto a finer grid
    xinterp = np.linspace(xmin, xmax, number_points)
    yinterp = np.interp(xinterp, xvals, yvals)

    # get points that are excluded at a certain confidence level
    excluded = yinterp > threshold
    edges = np.diff(1.0 * excluded)
    edges = np.insert(edges, 0, 0.0)

    # now group the edges in pairs to extract the individual simply connected regions that are excluded
    beginnings = xinterp[edges == -1] # gets all the transitions "excluded" -> "not excluded"
    endings = xinterp[edges == 1] # gets all the transitions "not excluded" -> "excluded"

    if len(beginnings) == len(endings):
        if beginnings[0] > endings[-1]:
            #confidence interval will be open on both sides
            beginnings = np.insert(beginnings, 0, xmin)
            endings = np.append(endings, xmax)

        # have a balanced situation, can just return the confidence interval as it is, nothing to be done
        pass
    elif len(beginnings) == len(endings) - 1:
        # confidence interval will be open to the left
        print("Warning: you have confidence intervals that are open on the left! If this is not expected, try decreasing the lower scan range.")
        beginnings = np.append(beginnings, -np.inf)
    elif len(endings) == len(beginnings) - 1:
        # confidence interval will be open to the right
        print("Warning: you have confidence intervals that are open on the right! If this is not expected, try increasing the upper scan range.")
        endings = np.append(endings, np.inf)
    else:
        raise Exception("Error: you seem to have a likelihood profile which isn't continuous! Please check your output!")

    assert len(beginnings) == len(endings) # this must now be ensured

    # prepare and return the result in the form of a list of tuples containing (beginning, end) of each simply connected piece
    result = np.array([beginnings, endings])
    retlist = np.hsplit(result, len(beginnings))

    retlist = [cur.flatten() for cur in retlist]

    return retlist

def PlotLikelihoodLandscape(data_infile, asimov_infile, plot_outdir, year = "6051", twodelta=False, inner_label = None):
    if not os.path.exists(plot_outdir):
        os.makedirs(plot_outdir)

    # get an instance of the analysis plotting configuration
    plotconf = Config(options = [])

    # load the data
    data = {}
    bestfit = {}

    if os.path.exists(data_infile):
        data_NLL = Tree2Dict(data_infile, "NLLscan")
        data_bestfit = Tree2Dict(data_infile, "bestFit")
        data["data"] = data_NLL
        bestfit["data"] = data_bestfit

    if os.path.exists(asimov_infile):
        asimov_NLL = Tree2Dict(asimov_infile, "NLLscan")
        asimov_bestfit = Tree2Dict(asimov_infile, "bestFit")
        data["asimov"] = asimov_NLL
        bestfit["asimov"] = asimov_bestfit

        cols = list(asimov_NLL.keys())
        number_rows = len(asimov_NLL[cols[0]])
        for row in range(number_rows):
        	print("   ".join([str(asimov_NLL[col][row]) for col in cols]))


    if len(data.keys()) == 0:
        raise Exception("Error: need at least one of data / Asimov to make any plots!")

    # look at the first piece of data to decide which kinds of plot to make
    representative = list(data.values())[0]
    available_columns = representative.keys()
    x_columns = [col for col in available_columns if "NLL" not in col]
    NLL_columns = [col for col in available_columns if "NLL" in col]

    if len(NLL_columns) != 1:
        raise NotImplementedError("Error: can not plot vector-valued quantities (yet).")
    NLL_column = NLL_columns[0]

    # some general plotting settings
    # TODO: put these somewhere more easily accessible
    colors_dict = {"asimov": ROOT.kBlue, "data": ROOT.kBlue}
    lw_dict = {"asimov": 2, "data": 3}
    ls_dict = {"asimov": 7, "data": 1}

    # prepare the label text
    plotconf._year = year

    if inner_label is None:
        runinfo = plotconf.get_run_info()
        lumi, energy = list(runinfo.values())[0]
        signaldesc = plotconf.signal[0]
        #lambdaval = plotconf.EFT_lambda
        #inner_label = f"#splitline{{#sqrt{{s}} = {energy} TeV, {lumi} fb^{{-1}}}}{{{signaldesc}, #Lambda = {lambdaval} TeV}}"
        inner_label = f"#splitline{{#sqrt{{s}} = {energy} TeV, {lumi} fb^{{-1}}}}{{{signaldesc}}}"

    domain_dims = len(x_columns)
    if domain_dims == 1:
        x_column = x_columns[0]
        print("Found 1D profiles --> will generate 1D plots")

        labels_dict = {"asimov": "expected", "data": "observed"}

        # prepare the data such that it can be plotted
        outfile_path = os.path.join(plot_outdir, "profile.pdf")
        xvals = []
        yvals = []
        labels = []
        colors = []
        xlabel = operator_namer(x_column, plotconf)
        ylabel = "- #Delta log(L)"
        if twodelta:
            ylabel = "- 2#Delta log(L)"
        lw = []
        ls = []

        def renormalizeValues(vals, name):
            newVals = []
            mini = np.min(np.array(vals))
            if mini < -1e-3:
                print(f"WARNING: The fit minimum and the likelihood scan minimum don't coincide for {name}. Going to renormalize to the likelihood scan minimum. Please check this!")
                for val in vals:
                    val = val - mini
                    newVals.append(val)
                return newVals
            else:
                return vals

        for cur_name, cur_data in data.items():
            cur_data[NLL_column] = renormalizeValues(cur_data[NLL_column], labels_dict[cur_name])
            xvals.append(cur_data[x_column])
            yvals.append(cur_data[NLL_column])
            labels.append(labels_dict[cur_name])
            colors.append(colors_dict[cur_name])
            lw.append(lw_dict[cur_name])
            ls.append(ls_dict[cur_name])

            # get the confidence interval and print it
            print("--------------------------------")
            print(f"Calculating {labels_dict[cur_name]} Confidence Intervals")
            print("--------------------------------")
            CI_68 = GetConfidenceInterval(cur_data[x_column], cur_data[NLL_column], 0.494475)
            print("have the following 68% CI:")
            for (cur_beginning, cur_ending) in CI_68:
                print(f"{xlabel}: [{cur_beginning}, {cur_ending}]")
            print("--------------------------------")

            CI_95 = GetConfidenceInterval(cur_data[x_column], cur_data[NLL_column], 1.92072)
            print("have the following 95% CI:")
            for (cur_beginning, cur_ending) in CI_95:
                print(f"{xlabel}: [{cur_beginning}, {cur_ending}]")
            print("--------------------------------")



        Plot1DProfile(xvals, yvals, labels, colors, outfile_path, twodelta, xlabel = xlabel, ylabel = ylabel, inner_label = inner_label, lw = lw, ls = ls)


    elif domain_dims == 2:
        print("Found 2D profiles --> will generate 2D plots")

        labels_dict = {"asimov": "expected", "data": "observed"}

        # make the structure of the data more explicit
        x_column = x_columns[0]
        y_column = x_columns[1]

        print(f"plotting along x: {x_column}")
        print(f"plotting along y: {y_column}")

        contour_levels = [1.15, 3.00] # this are the correct 1 and 2 sigma Neyman confidence interval for a 2-dimensional chisq distribution
        contour_labels = ["68% CL.", "95% CL."]
        contour_ls = [7, 1]
        plot_data = []
        labels = []
        colors = []
        xlabel = operator_namer(x_column, plotconf)
        ylabel = operator_namer(y_column, plotconf)
        lw = []
        plot_bestfit = []

        def renormalize_2D(data, name):
            dl = list(data)
            minx = miny = 0.0
            minz = 1e6

            for cell in dl:
                for triple in cell:
                    if triple[2] < minz:
                        minz = triple[2]
                        minx = triple[0]
                        miny = triple[1]

            if minz < -1e-3:
                print(f"WARNING: Bestfit minimum and minimum from interpolated likelihood landscape don't coincide for {name}. Going to use the minimum from the likelihood scan. Please check this!")

                for cell in dl:
                    for triple in cell:
                        triple[2] = triple[2] - minz

                return np.array(dl), minx, miny, True
            else:
                return [],0.0,0.0,False

        for cur_name, cur_data in data.items():
            # take the loaded data and interpolate it onto a very fine grid
            (new_xvals, new_yvals), new_zvals = RemoveOutliers(xvals = [cur_data[x_column], cur_data[y_column]],
                                                               zvals = cur_data[NLL_column])
            interpolated_data = Interpolate(xvals = new_xvals, yvals = new_yvals, zvals = new_zvals)

            tmp_interpolated_data, tmp_minx, tmp_miny, wrongMin = renormalize_2D(interpolated_data, cur_name)
            if(wrongMin):
                plot_data.append(tmp_interpolated_data)
                plot_bestfit.append([tmp_minx, tmp_miny])
            else:
                plot_data.append(interpolated_data)
                plot_bestfit.append([bestfit[cur_name][x_column][0], bestfit[cur_name][y_column][0]])

            labels.append(labels_dict[cur_name])
            colors.append(colors_dict[cur_name])

        # then, print the contour lines coming from this surface
        Plot2DContours(plot_data, labels, colors, os.path.join(plot_outdir, "contours.pdf"), contour_levels,
                       contour_labels = contour_labels, cont_ls = contour_ls, xlabel = "#mu", ylabel = "#mu_{Bkd}",
                       bestfit = plot_bestfit, inner_label = inner_label)

        for cur_plot_data, cur_label in zip(plot_data, labels):
            outfile_path = os.path.join(plot_outdir, f"heatmap_{cur_label}.pdf")
            Plot2DHeatmap(cur_plot_data, cur_label, outfile_path, xlabel = "#mu", zlabel = "-#Delta log(L)",
                          ylabel = "#mu_{Bkd}", bestfit = plot_bestfit[0], inner_label = inner_label)
    else:
        raise NotImplementedError(f"Error: can not perform plots with {domain_dims} x-dimensions (yet).")

if __name__ == "__main__":
    parser = ArgumentParser(description = "visualize output generated by LikelihoodLandscape")
    parser.add_argument("--data_infile", action = "store", dest = "data_infile", default = "", help = "path to file with input data")
    parser.add_argument("--asimov_infile", action = "store", dest = "asimov_infile", default = "", help = "path to directory holding Asimov results")
    parser.add_argument("--outdir", action = "store", dest = "plot_outdir", help = "path to directory that holds all generated plot")
    parser.add_argument("--year", action = "store", dest = "year", default = "6051", help = "data-taking periods used to make this plot, following WSMaker convention. Default: 6051, i.e. full Run 2")
    parser.add_argument("--twodelta", action = "store_true", dest = "twodelta", help = "Plot -2 Delta log(L) for 1D likelihood scans")
    args = vars(parser.parse_args())

    print("data_infile = {}".format(args["data_infile"]))
    print("asimov_infile = {}".format(args["asimov_infile"]))
    print("plot_outdir = {}".format(args["plot_outdir"]))

    PlotLikelihoodLandscape(**args)
